{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseball's Steroid Era\n",
    "\n",
    "### Using machine learning to find out who else was on the juice\n",
    "\n",
    "#### Chris Johnson - January 2018\n",
    "\n",
    "When I was a kid I collected baseball cards.  My favorite team was the Oakland A's.  In the late 1980's, the best part about the A's was the Bash Brothers, Jose Canseco and Mark McGwire.  They were my baseball heroes.  It turns out they were also pretty regular steroid users.  We know from the Mitchell report that more than 80 other players were juicing too.  I want to make a model that can predict which other sluggers may also have been using performance enhancing drugs based only on baseball performance stats.\n",
    "\n",
    "I'll use the The Lahman Baseball Database 2014 version (http://www.seanlahman.com/baseball-archive/statistics/) as the basis for this analysis.  My idea is to take the top sluggers in baseball history and split them into three categories.\n",
    "\n",
    "Category 1: Sluggers who played before the steroid era that I'll assume were clean\n",
    "\n",
    "Category 2: Sluggers who have been implicated as involved with performance enhancing drugs\n",
    "\n",
    "Category 3: Sluggers who had retired before 2014, played during the steroid era, and weren't implicated as involved with performance enhancing drugs\n",
    "\n",
    "Categories 1 & 2 will train and test a binary classifier.  I'll then make predictions using the Category 3 data.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Some Data\n",
    "\n",
    "My first task is to get a dataframe with all the top sluggers going back to Ruth (all time leader in career slugging percentage).  To determine sluggers I'll add a slugging percentage column to the dataframe, put it in order of descending slugging percentage, and keep top 1500 or so sluggers.  According to Wikipedia, slugging percentage (SLG) is defined as:\n",
    "\n",
    "$$\n",
    "SLG = \\frac{(1B + 2(2B) + 3(3B) + 4(HR))}{AB}\n",
    "$$\n",
    "\n",
    "Loosely following the lead of baseball-reference.com, I'll only include batters that have a minimum of:\n",
    "    \n",
    "    1) 3000 at bats and\n",
    "    2) 500 career games played\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "sqlite_file = 'lahman2014.sqlite'\n",
    "conn = sqlite3.connect(sqlite_file)\n",
    "#get all players with more than 3000 AB's and 500 games. also bring back info to calculate SLG\n",
    "Slugger_query = \"SELECT playerID as TheKey, sum(G) as GamesPlayed, sum(AB) as AtBats, sum(HR) as HomeRuns, sum(H) as Hits, sum([3B]) as Triples, sum([2B]) as Doubles FROM Batting GROUP BY playerID HAVING sum(G) >= 500 AND sum(AB) >= 3000\"\n",
    "#make a dataframe\n",
    "Sluggers = pandas.read_sql(Slugger_query, conn)\n",
    "#add column for singles\n",
    "Sluggers['Singles'] = Sluggers['Hits'] - Sluggers['Triples'] - Sluggers['Doubles'] - Sluggers['HomeRuns']\n",
    "#add column for SLG\n",
    "Sluggers['Slugging'] = (Sluggers['Singles'] + (2*Sluggers['Doubles']) + (3*Sluggers['Triples']) + (4*Sluggers['HomeRuns']))/Sluggers['AtBats']\n",
    "#just keep 1500 best sluggers\n",
    "DescendingSluggers = Sluggers.sort_values(by='Slugging',ascending=False)\n",
    "Best1500Sluggers = DescendingSluggers[:1500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add More Information\n",
    "\n",
    "I've got my list of the top sluggers from all baseball eras.  To better define the player's baseball era, I'll put in the start date and retirement date of each of these players.  Then I'll identify whether they retired before the steroid era.  I should toss their names in too.  To help control for changes in the early game, I'll only get data from after baseball's deadball era.  I'll date the end of the deadball era to the year that Babe Ruth started hitting more or less full time, 1919.  For later age based trends, I'll add in player birth year as well.\n",
    "\n",
    "In espn's estimation, the steroids era in baseball began in the late 1980's.  Jose Canseco was a late call up in 1985.  Mark Mcgwire, Barry Bonds, and Rafael Palmeiro made their major league debuts in 1986.  These four are part of the same baseball generation and seem to mark the arrival of a new kind of 'competitor'.  But, let's give the old guys a couple years to clear out.  I'll put the steroids era cutoff date at 1988.\n",
    "\n",
    "I'll also add in info from http://www.baseballssteroidera.com/bse-list-steroid-hgh-users-baseball.html that identifies players linked to steroids or human growth hormone.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after applying the deadball filter we have 1308 slugger's stats\n",
      "42 are linked to steroids or hgh according to baseballssteroidera.com\n",
      "after applying the retired filter we have 1178 slugger's stats\n",
      "39 retired players are linked to steroids or hgh\n"
     ]
    }
   ],
   "source": [
    "#get names and dates\n",
    "SluggerInfo_query = \"SELECT playerID as TheKey, nameFirst, nameLast, debut, finalGame, birthYear FROM MASTER\"\n",
    "SluggersInfo = pandas.read_sql(SluggerInfo_query, conn)\n",
    "#do an inner join on the two df's\n",
    "#this only keeps records that appear in both dataframes\n",
    "TheSluggersDf = pandas.merge(Best1500Sluggers, SluggersInfo, how='inner',left_on='TheKey', right_on='TheKey')\n",
    "\n",
    "#convert date columns to date data types\n",
    "#sqllite has number of ms since 1JAN1970, so have to adjust in the following way\n",
    "TheSluggersDf['debut'] = pandas.to_timedelta(TheSluggersDf['debut'], unit='ms') + pandas.Timestamp('1970-1-1')\n",
    "TheSluggersDf['finalGame'] = pandas.to_timedelta(TheSluggersDf['finalGame'], unit='ms') + pandas.Timestamp('1970-1-1')\n",
    "\n",
    "#many players on this list are still active.  the meta states that finalGame is blank for active players, but it\n",
    "#active players seem to return a date from 2014.  I'll just include an indicator for all players with\n",
    "#a finalGame in 2014 (1 is active, -1 is retired)\n",
    "TheSluggersDf['Active'] = np.where(TheSluggersDf['finalGame'].dt.year == 2014, 1,-1)\n",
    "\n",
    "#add boolean indicating whether player retired before the steroids era or not (1 is true, -1 is false)\n",
    "TheSteroidCutoff = np.datetime64('1988-04-04')\n",
    "TheSluggersDf['SteroidsEra'] = np.where(TheSluggersDf['finalGame']>=TheSteroidCutoff, 1, -1)\n",
    "\n",
    "#exclude deadball era players\n",
    "TheDeadballCutoff = np.datetime64('1919-04-19')\n",
    "NonDeadballSluggersDf = TheSluggersDf[TheSluggersDf['finalGame'] >= TheDeadballCutoff]\n",
    "print(\"after applying the deadball filter we have \" + str(NonDeadballSluggersDf.shape[0]) + \" slugger's stats\")\n",
    "\n",
    "#add in info about players linked to steroids and hgh\n",
    "UsersDf = pandas.read_csv('Users.csv')\n",
    "#do a left join on the two df's\n",
    "#this only keeps all records from NonDeadballSluggersDf and only adds info from matches in UsersDf\n",
    "TheSluggersUsersDf = pandas.merge(NonDeadballSluggersDf, UsersDf, how='left',left_on=['nameFirst','nameLast'], right_on=['fName','lName'])\n",
    "#drop new fName,lName columns\n",
    "TheCleanerSluggersDf = TheSluggersUsersDf.drop(['fName','lName'], axis=1)\n",
    "print(str(NonDeadballSluggersDf.shape[0] - TheCleanerSluggersDf['status'].isnull().sum()) + \" are linked to steroids or hgh according to baseballssteroidera.com\")\n",
    "#play the 1,-1 game on status.  1 means a link to steroids or hgh\n",
    "TheCleanerSluggersDf['status'] = np.where(TheCleanerSluggersDf['status'].isnull(), -1, 1)\n",
    "#TheCleanerSluggersDf.head()\n",
    "\n",
    "#make a dataframe for just retired players\n",
    "RetiredSluggers = TheCleanerSluggersDf[TheCleanerSluggersDf['Active'] < 0]\n",
    "\n",
    "print(\"after applying the retired filter we have \" + str(RetiredSluggers.shape[0]) + \" slugger's stats\")\n",
    "LinkedSluggers = RetiredSluggers[RetiredSluggers['status'] > 0]\n",
    "print(str(LinkedSluggers.shape[0]) + \" retired players are linked to steroids or hgh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Data\n",
    "\n",
    "It's time to look for features that might distinguish between players who to took steroids and players who did not.\n",
    "\n",
    "Although it's not a sure assumption that all sluggers who played in the pre-steroid era were clean, it's the one I'm going with here.  There are some striking differences in achievements between the eras.  There is a pretty good story on the subject from Bleacher Report (http://bleacherreport.com/articles/1648362-proof-that-the-steroid-era-power-surge-in-baseball-has-been-stopped).\n",
    "\n",
    "Some quotes from the report:\n",
    "\n",
    "\"The Steroid Era saw an explosion of 40-homer seasons, which have since gone back to being special occasions...42 percent of MLB's 40-homer seasons happened\" between 1996 and 2006.\n",
    "\n",
    "\"Old guys were doing things in the juiced-up era that old guys generally have no business doing.  Case in point, there have been 24 cases in MLB history of a player 35 years old or older hitting at least 40 HRs. Of those, 13 occurred between 1996 and 2006.\"\n",
    "\n",
    "ESPN has a good summary of steroid era facts too (http://www.espn.com/mlb/topics/_/page/the-steroids-era). \n",
    "\n",
    "\"While just three players reached the 50-home run mark in any season between 1961 and 1994, many sluggers would start to surpass that number in the mid-90s.\"\n",
    "\n",
    "\"Sosa finished second in the NL in home runs with 66, 26 more than his previous season high.\"\n",
    "\n",
    "\"Bonds notched 73 homers despite failing to reach the 50-home run plateau in any prior season.\"\n",
    "\n",
    "It seems year over year home run total differences and late career performance improvements are potential areas of interest to explore.\n",
    "\n",
    "I'll ask five questions of the data.\n",
    "\n",
    "Q1: Did this player hit 40 homeruns in a season at 35 years of age or more?\n",
    "\n",
    "Q2: Did this player ever have a season (for >= 400 AB's) that his HR total change was>=15 HR from previous season?\n",
    "\n",
    "Q3: Did this player ever have a season (for >= 400 AB's) that his HR total change was>=20 HR from previous season?\n",
    "\n",
    "Q4: Is this players mean over 35 SLG better than his mean SLG from the age 27-30?\n",
    "\n",
    "Q5: Is this players mean over 35 HR per AB better than his mean HR per AB from the age 27-30?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write a function to ask a series of questions for each player:\n",
    "\n",
    "#1) did this player hit 40 homeruns in a season at 35 years of age or more?\n",
    "#2 and 3) did this player ever have a season (for >= 400 AB's) that his HR total change was>=15 HR from previous season? >= 20?\n",
    "# for q's 2 and 3 need to control for rookies.  make sure players are mature before testing.  say 28 or older\n",
    "#read this if you think this is a bad threshold\n",
    "#https://www.baseballprospectus.com/news/article/9933/how-do-baseball-players-age-investigating-the-age-27-theory/\n",
    "#4) is this players mean over 35 SLG better than his mean SLG from the age 27-30?\n",
    "#5) is this players mean over 35 HR per AB better than his mean HR per AB from the age 27-30?\n",
    "\n",
    "#The input to the function is a series of player ids and a corresponsing series of birth years\n",
    "\n",
    "def GetSomeAnswers(ThePlayerInfo):\n",
    "    #an empty dataframe to keep all the answers in\n",
    "    DfColumns=['TheKey','Q1','Q2','Q3','Q4','Q5']\n",
    "    DfList = []\n",
    "    for row in ThePlayerInfo.itertuples():\n",
    "        ThePlayerId = row.TheKey\n",
    "        TheBirthYear = row.birthYear\n",
    "        \n",
    "        SluggerTs_query = \"SELECT yearID as TheKey, AB, HR, H, [3B], [2B] FROM Batting WHERE playerID = '\" + ThePlayerId + \"' GROUP BY yearID HAVING AB >= 400\"\n",
    "        SluggersTs = pandas.read_sql(SluggerTs_query, conn)\n",
    "        #add column for singles\n",
    "        SluggersTs['Singles'] = SluggersTs['H'] - SluggersTs['3B'] - SluggersTs['2B'] - SluggersTs['HR']\n",
    "        #add column for SLG\n",
    "        SluggersTs['Slugging'] = (SluggersTs['Singles'] + (2*SluggersTs['2B']) + (3*SluggersTs['3B']) + (4*SluggersTs['HR']))/SluggersTs['AB']\n",
    "        #add column for age\n",
    "        SluggersTs['Age'] = SluggersTs['TheKey'] - int(TheBirthYear)\n",
    "        #add column for HR change\n",
    "        SluggersTs['Subtractor'] = SluggersTs['HR'].shift(periods=1)\n",
    "        SluggersTs['HrChange'] = SluggersTs['HR'] - SluggersTs['Subtractor']\n",
    "        CleanSluggersTs = SluggersTs.drop(['Subtractor'], axis=1)\n",
    "        #add column for HR/AB\n",
    "        CleanSluggersTs['HrRate'] = SluggersTs['HR']/SluggersTs['AB']\n",
    "        \n",
    "        #answer Q1 did this player hit 40 homeruns in a season at 35 years of age or more?\n",
    "        Over35HrDf = CleanSluggersTs[CleanSluggersTs['Age'] >= 35].HR\n",
    "        Answer1 = (Over35HrDf >= 40).any()\n",
    "        if Answer1:\n",
    "            Over35Hr = 1\n",
    "        else:\n",
    "            Over35Hr = -1\n",
    "        #print(Over35Hr,Answer1)\n",
    "        #answer Q2 did this player ever have a seasonthat he hit more/less than 15 HR than the previous season?\n",
    "        GtPos15Df = CleanSluggersTs[CleanSluggersTs['Age'] >= 28].HrChange.abs()\n",
    "        Answer2 = (GtPos15Df >= 15).any()\n",
    "        if Answer2:\n",
    "            GtPos15 = 1\n",
    "        else:\n",
    "            GtPos15 = -1\n",
    "        #print(GtPos15,Answer2)\n",
    "        #answer Q3 did this player ever have a seasonthat he hit more/less than 20 HR than the previous season?\n",
    "        GtPos20Df = CleanSluggersTs[CleanSluggersTs['Age'] >= 28].HrChange.abs()\n",
    "        Answer3 = (GtPos20Df >= 20).any()\n",
    "        if Answer3:\n",
    "            GtPos20 = 1\n",
    "        else:\n",
    "            GtPos20 = -1\n",
    "        #print(GtPos20,Answer3)\n",
    "        #answer Q4 is this players mean over 35 SLG better than his mean SLG from the age 27-30?\n",
    "        Slg35 = CleanSluggersTs[CleanSluggersTs['Age'] >= 35].Slugging.mean()\n",
    "        SlgPrime = CleanSluggersTs[(CleanSluggersTs['Age'] >= 27) & (CleanSluggersTs['Age'] <= 30)].Slugging.mean()\n",
    "        #print(\"slg means\",[Slg35,SlgPrime])\n",
    "        Answer4 = Slg35 > SlgPrime\n",
    "        if Answer4:\n",
    "            SlgTest = 1\n",
    "        else:\n",
    "            SlgTest = -1\n",
    "        #print(SlgTest,Answer4)\n",
    "        #answer Q5 is this players mean over 35 HR per AB better than his mean HR per AB from the age 27-30?\n",
    "        HrAb35 = CleanSluggersTs[CleanSluggersTs['Age'] >= 35].HrRate.mean()\n",
    "        HrAbPrime = CleanSluggersTs[(CleanSluggersTs['Age'] >= 27) & (CleanSluggersTs['Age'] <= 30)].HrRate.mean()\n",
    "        #print(\"HrAb\",[HrAb35,HrAbPrime])\n",
    "        Answer5 = HrAb35 > HrAbPrime\n",
    "        if Answer5:\n",
    "            HrAbTest = 1\n",
    "        else:\n",
    "            HrAbTest = -1\n",
    "        #print(HrAbTest,Answer5)\n",
    "        \n",
    "        DfList.append([ThePlayerId,Over35Hr,GtPos15,GtPos20,SlgTest,HrAbTest])\n",
    "    \n",
    "    SomeAnswers = pandas.DataFrame(DfList,columns=DfColumns)\n",
    "    return(SomeAnswers)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#input to the function are all the RetiredSluggers\n",
    "MyPlayerInfo = pandas.concat([RetiredSluggers['TheKey'], RetiredSluggers['birthYear']], axis=1)\n",
    "\n",
    "TheAnswers = GetSomeAnswers(MyPlayerInfo)\n",
    "#TheAnswers.head()\n",
    "\n",
    "#then i'll add the answers (-1 no, 1 yes) to the retired sluggers df\n",
    "#do a left join on the two df's\n",
    "#this only keeps all records from RetiredSluggers and only adds info from matches in TheAnswers\n",
    "RetiredSluggersAnswers = pandas.merge(RetiredSluggers, TheAnswers, how='left',left_on=['TheKey'], right_on=['TheKey'])\n",
    "#RetiredSluggersAnswers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data for the Classifier\n",
    "\n",
    "At this point there are some features in the dataset I can use to train a model.  I'll break the data into three parts.  There are people I'm assuming didn't use steroids or hgh (SteroidsEra = -1).  There is a list of people linked to steroids or hgh (status = 1). There are also some who played during the steroids era that aren't linked to steroids or hgh (SteroidsEra*status < 0).  That last group will be the group i'll make the predictions on. The rest I'll use as a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test group (722, 23)\n",
      "38 train/test players are linked to steroids or hgh\n"
     ]
    }
   ],
   "source": [
    "#add indicator for train/test or predictor and make the groups\n",
    "RetiredSluggersAnswers['PredictionGroup'] = RetiredSluggersAnswers['SteroidsEra']*RetiredSluggersAnswers['status']\n",
    "PredictionGroup = RetiredSluggersAnswers[RetiredSluggersAnswers['PredictionGroup']< 0]\n",
    "#print(\"prediction group\",PredictionGroup.shape)\n",
    "LinkedPredictionSluggers = PredictionGroup[PredictionGroup['status'] > 0]\n",
    "#print(str(LinkedPredictionSluggers.shape[0]) + \" prediction group players are linked to steroids or hgh\")\n",
    "#print(LinkedPredictionSluggers)\n",
    "TrainTestGroup = RetiredSluggersAnswers[RetiredSluggersAnswers['PredictionGroup']> 0]\n",
    "print(\"train test group\",TrainTestGroup.shape)\n",
    "LinkedTrainTestSluggers = TrainTestGroup[TrainTestGroup['status'] > 0]\n",
    "print(str(LinkedTrainTestSluggers.shape[0]) + \" train/test players are linked to steroids or hgh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now i'll split the train/test data into train and test groups keeping approximately equal ratios of confirmed users in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Data\n",
      "-1    0.947368\n",
      " 1    0.052632\n",
      "Name: status, dtype: float64\n",
      "Training Data\n",
      "-1    0.948276\n",
      " 1    0.051724\n",
      "Name: status, dtype: float64\n",
      "Test Data\n",
      "-1    0.945\n",
      " 1    0.055\n",
      "Name: status, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#make train and test datasets with approximately equal ratios of confirmed users\n",
    "#import sklearn shuffle split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "#make a unique index for each entry with nice ordered integers\n",
    "TrainTestGroupDf = TrainTestGroup.reset_index(drop=True)\n",
    "#just keep the fields to use for training\n",
    "TrainTestGroupCopy = TrainTestGroupDf[['Q1','Q2','Q3','Q4','Q5','status']].copy()\n",
    "\n",
    "#figure out the frequency of each score for the whole data set\n",
    "print('All Data')\n",
    "print(TrainTestGroupCopy['status'].value_counts() / len(TrainTestGroupCopy['status']))\n",
    "\n",
    "#do stratified sampling\n",
    "#see: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=200, random_state=1234)\n",
    "for train_index, test_index in split.split(TrainTestGroupCopy, TrainTestGroupCopy[\"status\"]):\n",
    "    train_set = TrainTestGroupCopy.loc[train_index]\n",
    "    test_set = TrainTestGroupCopy.loc[test_index]\n",
    "    \n",
    "#compare test and training data sets to see that ratios approximately match\n",
    "print('Training Data')\n",
    "print(train_set[\"status\"].value_counts() / len(train_set))\n",
    "print('Test Data')\n",
    "print(test_set[\"status\"].value_counts() / len(test_set))\n",
    "#print(train_set)\n",
    "#set up x and y for the train set\n",
    "train_X = train_set[['Q1','Q2','Q3','Q4','Q5']]\n",
    "train_y = train_set[['status']]\n",
    "#reshape the labels to make this work\n",
    "labels = train_y['status']\n",
    "#set up x and y for the test set\n",
    "test_X = test_set[['Q1','Q2','Q3','Q4','Q5']]\n",
    "test_y = test_set[['status']]\n",
    "#reshape the labels to make this work\n",
    "labelsTest = test_y['status']\n",
    "#print(train_y.shape)\n",
    "#print(train_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection/Evaluation\n",
    "\n",
    "Here I'll try out an ensemble method, Adaptive Boosting (Adaboost).  In general, ensemble methods take a combination of weak learners in order to make a stronger learner.  Adaboost iterates through a classifier making predictions for each iteration.  If a predecessor classifier is wrong, then going forward it puts more weight on the incorrect predictions.  I'm using decistion trees as the weak learners here.  \n",
    "\n",
    "To evaluate this model I'll use cross validation scores, in this case the area under the ROC curve.  I'll use 20 folds during cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done. Here are the auc scores:  [ 0.9         0.74        0.71        0.98        0.42        0.5         0.87\n",
      "  0.38        1.          0.98        0.98        0.44        0.44        0.96\n",
      "  0.96        0.85416667  0.4375      0.39583333  1.          0.85416667]\n",
      "And the mean auc score (mean estimate of classification accuracy):  0.740083333333\n"
     ]
    }
   ],
   "source": [
    "#get cross validation scores (small dataset here) for the adaboost classifier using \n",
    "#decision tree stumps as the weak learners\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import numpy as np\n",
    "\n",
    "#Use decision trees as weak learners\n",
    "TreeStump = DecisionTreeClassifier(max_depth=3, min_samples_leaf=10)\n",
    "\n",
    "clf = AdaBoostClassifier(base_estimator=TreeStump,n_estimators=100)\n",
    "#specify 20 fold\n",
    "scores = cross_val_score(clf, train_X, labels,scoring='roc_auc',cv=20)\n",
    "print('All done. Here are the auc scores: ',scores)\n",
    "print('And the mean auc score (mean estimate of classification accuracy): ',np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results from cross validation indicate this approach has potential.  I'll train a model and get some metrics about how it behaves on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      clean       0.95      1.00      0.97       189\n",
      "      dirty       1.00      0.09      0.17        11\n",
      "\n",
      "avg / total       0.95      0.95      0.93       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use adaboost then make predictions on the test data\n",
    "Ada = clf.fit(train_X, labels)\n",
    "yPred = Ada.predict(test_X)\n",
    "target_names = ['clean', 'dirty']\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(labelsTest, yPred, target_names=target_names))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the positive predictions, or precision, is high for both clean and dirty players.  That means when the model actually calls someone out for using, it's usually right.  But, the ratio of positive instances correctly detected, or recall, is pretty low for dirty players.  That means it's a pretty conservative classifier with respect to going out on a limb to identify those who used performance enhancing drugs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict who else used Performance Enhancing Drugs\n",
    "\n",
    "This is the part where I name names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "according to my model, these guys may also have been using steroids or hgh\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nameFirst</th>\n",
       "      <th>nameLast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Larry</td>\n",
       "      <td>Walker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mike</td>\n",
       "      <td>Schmidt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ellis</td>\n",
       "      <td>Burks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Luis</td>\n",
       "      <td>Gonzalez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Greg</td>\n",
       "      <td>Vaughn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Steve</td>\n",
       "      <td>Finley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Darrell</td>\n",
       "      <td>Evans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Terry</td>\n",
       "      <td>Steinbach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Jay</td>\n",
       "      <td>Bell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nameFirst   nameLast\n",
       "0       Larry     Walker\n",
       "11       Mike    Schmidt\n",
       "17      Ellis      Burks\n",
       "58       Luis   Gonzalez\n",
       "79       Greg     Vaughn\n",
       "153     Steve     Finley\n",
       "193   Darrell      Evans\n",
       "233     Terry  Steinbach\n",
       "250       Jay       Bell"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now see if any of the other guys from the prediction group are dirty\n",
    "\n",
    "#make a unique index for each entry with nice ordered integers\n",
    "PredictionGroupDf = PredictionGroup.reset_index(drop=True)\n",
    "#just keep the fields to use for training\n",
    "PredictionGroupCopy = PredictionGroupDf[['Q1','Q2','Q3','Q4','Q5','status']].copy()\n",
    "#set up x and y for the prediction set\n",
    "Pg_X = PredictionGroupCopy[['Q1','Q2','Q3','Q4','Q5']]\n",
    "#see who may have taken steroids or hgh\n",
    "PgPred = Ada.predict(Pg_X)\n",
    "#add the predictions to the PredictionGroupDf\n",
    "PredictionGroupDf['Predictions'] = PgPred\n",
    "NonDeadballSluggersDf = TheSluggersDf[TheSluggersDf['finalGame'] >= TheDeadballCutoff]\n",
    "PotentialUsers = PredictionGroupDf[PredictionGroupDf['Predictions'] > 0]\n",
    "PotentialUsersNames = PotentialUsers[['nameFirst', 'nameLast']]\n",
    "\n",
    "print(\"according to my model, these guys may also have been using steroids or hgh\")\n",
    "PotentialUsersNames\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The first name that jumps out to me is Terry Steinbach.  He was on those Bash Brother teams in Oakland.  According to a blog (http://joeposnanski.com/32-flukiest-home-run-seasons/), he had the 18th flukiest home run season ever in 1996.  My model didn't know he played with Canseco and McGwire, but it saw that he hit way more homers in '96 than in any other season.  It's tough to explain this aberration, but one writer has not ruled out some sort of deal with Lucifer (http://twinsdaily.com/blog/65/entry-6196-steinbach-in-96-how-do-you-explain-it/).\n",
    "\n",
    "Larry Walker and Ellis Burks had some monster seasons in '96 and '97.  They are on some people's radar (http://bleacherreport.com/articles/171276-can-anyone-be-trusted-looking-at-the-steroid-era, http://bleacherreport.com/articles/1011219-most-suspicious-one-year-position-player-wonders-in-mlb-history).  Again, I think it was the home run total jump that my model saw.  Also they played for the Rockies during that time frame with Walt Weiss, another Bash Brother teammate from Oakland.  Of course, home run totals in the thin air of Coors Field are bigger than in other parks...\n",
    "\n",
    "Mike Schmidt supposedly used amphetamines (https://nyulocal.com/juicin-in-the-majors-a-history-of-steroids-in-baseball-d2facd1cbcfb), but I'm not convinced he used steroids.  He is from a baseball generation that I tried to exclude from consideration, but he didn't retire until 1989, so he got looked at here.  I think the model saw his rough offensive year in '78 and drew some questionable conclusions.  The thing is, and this is in contrast especially to Steinbach and Burks, Schmidt's bad year in '78 was the aberration.  He didn't just have one amazing year."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
